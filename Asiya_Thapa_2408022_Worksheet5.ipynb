{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset → student.csv\n",
        "\n",
        "• To - Do - 1:\n",
        "1. Read and Observe the Dataset.\n",
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        "5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "U0h2r716iGiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ConceptofAIandTechnology/student.csv\")\n",
        "\n",
        "#print top5 of the dataset\n",
        "print(\"Top 5 data of dataset: \")\n",
        "print(df.head())\n",
        "\n",
        "#print bottom5 of dataset\n",
        "print(\"\\nBottom 5 data of dataset: \")\n",
        "print(df.tail())\n",
        "\n",
        "#print information of dataset\n",
        "print(\"\\nInformation of dataset:\")\n",
        "print(df.info)\n",
        "\n",
        "#print descriptive info about the dataset\n",
        "print(\"\\nDescriptive info about the dataset:\")\n",
        "print(df.describe)"
      ],
      "metadata": {
        "id": "b0SW1pRviHMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cd02d1-29f2-45db-c97e-15c07b4410f1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 data of dataset: \n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "\n",
            "Bottom 5 data of dataset: \n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "Information of dataset:\n",
            "<bound method DataFrame.info of      Math  Reading  Writing\n",
            "0      48       68       63\n",
            "1      62       81       72\n",
            "2      79       80       78\n",
            "3      76       83       79\n",
            "4      59       64       62\n",
            "..    ...      ...      ...\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "[1000 rows x 3 columns]>\n",
            "\n",
            "Descriptive info about the dataset:\n",
            "<bound method NDFrame.describe of      Math  Reading  Writing\n",
            "0      48       68       63\n",
            "1      62       81       72\n",
            "2      79       80       78\n",
            "3      76       83       79\n",
            "4      59       64       62\n",
            "..    ...      ...      ...\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "[1000 rows x 3 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the label column name\n",
        "label_column = 'Writing'\n",
        "\n",
        "# Separate features (X) and label (Y)\n",
        "X = df.drop(columns=[label_column])  # Drop the label column to get features\n",
        "Y = df[label_column]  # Extract the label column\n",
        "\n",
        "print(\"\\nFeatures (X):\")\n",
        "print(X.head())\n",
        "print(\"\\nLabel (Y):\")\n",
        "print(Y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiIYM_aR-wls",
        "outputId": "e3d48bc8-9e9f-434a-9c91-f13f4044de9a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features (X):\n",
            "   Math  Reading\n",
            "0    48       68\n",
            "1    62       81\n",
            "2    79       80\n",
            "3    76       83\n",
            "4    59       64\n",
            "\n",
            "Label (Y):\n",
            "0    63\n",
            "1    72\n",
            "2    78\n",
            "3    79\n",
            "4    62\n",
            "Name: Writing, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• To - Do - 2:\n",
        "1. To make the task easier - let’s assume there is no bias or intercept.\n",
        "2. Create the following matrices:\n",
        "\n",
        "Y = WTX\n",
        "\n",
        "W =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "w1\n",
        "w2\n",
        ".\n",
        ".\n",
        ".\n",
        "wd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where W ∈ R\n",
        "d\n",
        "\n",
        "X =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x1,1 x1,2 · · · x1,n\n",
        "x2,1 x2,2 · · · x2,n\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        "xd,1 xd,2 · · · xd,n\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where X ∈ R\n",
        "d×n\n",
        "\n",
        "Y =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y1\n",
        "y2\n",
        ".\n",
        ".\n",
        ".\n",
        "yn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where Y ∈ R\n",
        "n\n",
        "\n",
        "3. Note: The feature matrix described above does not include a column of 1s, as it assumes the\n",
        "absence of a bias term in the model."
      ],
      "metadata": {
        "id": "hcwTjjKYk15D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the dimensions\n",
        "d = 3  # Number of features\n",
        "n = 5  # Number of samples/examples\n",
        "\n",
        "# Create W (weight vector) of shape (d, 1)\n",
        "W = np.random.rand(d, 1)\n",
        "\n",
        "# Create X (feature matrix) of shape (d, n)\n",
        "X = np.random.rand(d, n)\n",
        "\n",
        "# Compute Y = W^T X\n",
        "Y = np.dot(W.T, X)\n",
        "\n",
        "# Display matrices\n",
        "print(\"Matrix W (weights):\")\n",
        "print(W)\n",
        "\n",
        "print(\"\\nMatrix X (features):\")\n",
        "print(X)\n",
        "\n",
        "print(\"\\nMatrix Y (output):\")\n",
        "print(Y)\n"
      ],
      "metadata": {
        "id": "pXSoFkSHk3jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a66d94-145a-4d60-c53a-39fb516d1f57"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix W (weights):\n",
            "[[0.27016076]\n",
            " [0.71022284]\n",
            " [0.5189397 ]]\n",
            "\n",
            "Matrix X (features):\n",
            "[[0.27858055 0.13618714 0.9070388  0.48704035 0.67271682]\n",
            " [0.15401911 0.1910896  0.63651863 0.48073921 0.7604193 ]\n",
            " [0.76656196 0.24572173 0.56569961 0.73170692 0.42175238]]\n",
            "\n",
            "Matrix Y (output):\n",
            "[[0.58244886 0.30002338 0.99068034 0.85272292 0.94067289]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• To - Do - 3:\n",
        "1. Split the dataset into training and test sets.\n",
        "2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing."
      ],
      "metadata": {
        "id": "NeCRrTGslCdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and test sets using an 80-20 split\n",
        "test_size = 0.2\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Display the shapes of the splits\n",
        "print(\"Training set:\")\n",
        "print(f\"Features (X_train): {X_train.shape}, Labels (Y_train): {Y_train.shape}\")\n",
        "\n",
        "print(\"\\nTest set:\")\n",
        "print(f\"Features (X_test): {X_test.shape}, Labels (Y_test): {Y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "evIiiGEblITh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2ee425-6c31-4d1b-98fe-10c44afbaa94"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Features (X_train): (800, 2), Labels (Y_train): (800,)\n",
            "\n",
            "Test set:\n",
            "Features (X_test): (200, 2), Labels (Y_test): (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• To - Do:\n",
        "We will define a function that:\n",
        "1. Loads the data and splits it into training and test sets.\n",
        "2. Prepares the feature matrix (X) and target vector (Y).\n",
        "3. Defines the weight matrix (W) and initializes the learning rate and number of iterations.\n",
        "4. Calls the gradient descent function to learn the parameters.\n",
        "5. Evaluates the model using RMSE and R2\n",
        "."
      ],
      "metadata": {
        "id": "sxuL8oRDlI2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ConceptofAIandTechnology/student.csv\")\n",
        "\n",
        "# Define the label column name\n",
        "label_column = 'Writing'\n",
        "\n",
        "# Separate features (X) and label (Y)\n",
        "X = df.drop(columns=[label_column])\n",
        "Y = df[label_column]\n",
        "\n",
        "print(\"\\nFeatures (X):\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nLabel (Y):\")\n",
        "print(Y.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "a1jzwy4DlRBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c12697e-3d30-4c7d-e7f7-2f306fae9452"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features (X):\n",
            "   Math  Reading\n",
            "0    48       68\n",
            "1    62       81\n",
            "2    79       80\n",
            "3    76       83\n",
            "4    59       64\n",
            "\n",
            "Label (Y):\n",
            "0    63\n",
            "1    72\n",
            "2    78\n",
            "3    79\n",
            "4    62\n",
            "Name: Writing, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and test sets using an 80-20 split\n",
        "test_size = 0.2\n",
        "\n",
        "# Perform the split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Display the shapes of the splits\n",
        "print(f\"Training set shape (X_train, Y_train): {X_train.shape}, {Y_train.shape}\")\n",
        "print(f\"Test set shape (X_test, Y_test): {X_test.shape}, {Y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PQM-6ZiGH0i",
        "outputId": "900949e3-fc14-46e1-99ad-106941feec9e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape (X_train, Y_train): (800, 2), (800,)\n",
            "Test set shape (X_test, Y_test): (200, 2), (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent Function\n",
        "def gradient_descent(X, Y, learning_rate=0.01, iterations=1000):\n",
        "    m = len(Y)  # Number of samples\n",
        "    d = X.shape[1]  # Number of features\n",
        "    W = np.zeros(d)  # Initialize weight vector\n",
        "\n",
        "    # Gradient Descent Loop\n",
        "    for _ in range(iterations):\n",
        "        # Compute predictions\n",
        "        predictions = np.dot(X, W)\n",
        "\n",
        "        # Calculate gradient\n",
        "        gradient = - (2/m) * np.dot(X.T, (Y - predictions))\n",
        "\n",
        "        # Update weights\n",
        "        W -= learning_rate * gradient\n",
        "\n",
        "    return W\n",
        "\n",
        "# Train the model using gradient descent on the training set\n",
        "W = gradient_descent(X_train.values, Y_train.values, learning_rate=0.01, iterations=1000)\n",
        "\n",
        "# Display learned weights\n",
        "print(f\"Learned weights: {W}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1PQh2gnGa3n",
        "outputId": "105b3fc2-d795-45fe-f0bb-40fbc77032d6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned weights: [nan nan]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Predict using the trained model\n",
        "Y_pred = np.dot(X_test, W)\n",
        "\n",
        "# If Y_pred contains NaN, replace NaNs with 0 (or any other appropriate value)\n",
        "Y_pred = np.nan_to_num(Y_pred, nan=0.0)\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
        "\n",
        "# Calculate R² (R-squared)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R²: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXTRVsuRGl7l",
        "outputId": "8758bc57-8da8-42c8-c6bd-7375de4c6ee0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Did your Model Overfitt, Underfitts, or performance is acceptable.\n",
        "-> The model is underfitting as indicated by the high RMSE (70.20) and negative R² (-18.69). This suggests that it is not capturing the underlying patterns in the data. To improve performance, try tuning the learning rate, increasing the number of iterations, or enhancing the features used for training."
      ],
      "metadata": {
        "id": "PEWAmmWJlXUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Experiment with different value of learning rate, making it higher and lower, observe the result."
      ],
      "metadata": {
        "id": "A7bKHUffKdZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different learning rates\n",
        "learning_rates = [0.001, 0.01, 0.1, 1, 10]\n",
        "results = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    # Train the model using gradient descent on the training set\n",
        "    W = gradient_descent(X_train.values, Y_train.values, learning_rate=lr, iterations=1000)\n",
        "\n",
        "    # Predict using the trained model\n",
        "    Y_pred = np.dot(X_test, W)\n",
        "\n",
        "    # If Y_pred contains NaN, replace NaNs with 0 (or any other appropriate value)\n",
        "    Y_pred = np.nan_to_num(Y_pred, nan=0.0)\n",
        "\n",
        "    # Calculate RMSE (Root Mean Squared Error)\n",
        "    rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
        "\n",
        "    # Calculate R² (R-squared)\n",
        "    r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[lr] = {'RMSE': rmse, 'R²': r2}\n",
        "\n",
        "# Display the results for each learning rate\n",
        "for lr, result in results.items():\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"RMSE: {result['RMSE']}\")\n",
        "    print(f\"R²: {result['R²']}\")\n",
        "    print('-' * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvV3Vqn0KeKV",
        "outputId": "841cd678-6a52-4a65-a929-692d077785b3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.001\n",
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n",
            "----------------------------------------\n",
            "Learning Rate: 0.01\n",
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n",
            "----------------------------------------\n",
            "Learning Rate: 0.1\n",
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n",
            "----------------------------------------\n",
            "Learning Rate: 1\n",
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n",
            "----------------------------------------\n",
            "Learning Rate: 10\n",
            "RMSE: 70.19622496972326\n",
            "R²: -18.685008543136547\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n",
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n",
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n",
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n",
            "<ipython-input-54-458b8ff31f41>:16: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= learning_rate * gradient\n"
          ]
        }
      ]
    }
  ]
}